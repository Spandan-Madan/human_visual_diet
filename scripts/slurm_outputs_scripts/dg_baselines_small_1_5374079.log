1
Environment:
	Python: 3.8.11
	PyTorch: 1.9.1+cu102
	Torchvision: 0.10.1+cu102
	CUDA: 10.2
	CUDNN: 7605
	NumPy: 1.21.2
	PIL: 8.3.1
Args:
	algorithm: Mixup
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: DGMaterials
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	output_dir: train_output_small_long/Mixup
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [1]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 8
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	mixup_alpha: 0.2
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  epoch         loss          mem_gb        step          step_time    
0.0395341765  0.0410733453  0.0356171735  0.0337054530  0.0000000000  2.7567667961  1.0242199898  0             0.3361020088 
0.4950358670  0.4981753131  0.4818783542  0.4864033205  0.0429338104  1.8214470649  1.0242199898  300           0.1341108600 
0.5066635659  0.5064042934  0.4932558140  0.4994275082  0.0858676208  1.4665188724  1.0242199898  600           0.1341882173 
0.5651419474  0.5657245081  0.5574776386  0.5591097753  0.1288014311  1.3434252089  1.0242199898  900           0.1360706290 
0.5816890574  0.5817531306  0.5798032200  0.5864462573  0.1717352415  1.2743938821  1.0242199898  1200          0.1355641190 
0.6058388938  0.6081574240  0.5977280859  0.6036210104  0.2146690519  1.2283817986  1.0242199898  1500          0.1359642824 
0.6195595785  0.6137388193  0.6114847943  0.6165020753  0.2576028623  1.1724325310  1.0242199898  1800          0.1364898165 
0.6298635087  0.6279785331  0.6210375671  0.6273078574  0.3005366726  1.1292539003  1.0242199898  2100          0.1347788254 
0.6192196920  0.6143828265  0.6230053667  0.6318162301  0.3434704830  1.0898338564  1.0242199898  2400          0.1344639071 
0.6411692099  0.6364221825  0.6189087657  0.6214398168  0.3864042934  1.0728889545  1.0242199898  2700          0.1359263333 
0.6326362677  0.6299821109  0.6288729875  0.6320309146  0.4293381038  1.0946845260  1.0242199898  3000          0.1346085930 
0.6571081018  0.6508765653  0.6488193202  0.6543580936  0.4722719141  1.0699863324  1.0242199898  3300          0.1346560121 
0.6567145489  0.6512343470  0.6437745975  0.6477744382  0.5152057245  1.0425260907  1.0242199898  3600          0.1349381940 
0.6577342087  0.6497316637  0.6288014311  0.6363246028  0.5581395349  1.0361922500  1.0242199898  3900          0.1437139471 
0.6714727822  0.6654740608  0.6567262970  0.6602976957  0.6010733453  1.0368308280  1.0242199898  4200          0.1425975100 
0.6648718270  0.6551699463  0.6458497317  0.6535709174  0.6440071556  1.0168866552  1.0242199898  4500          0.1430280534 
0.6770361890  0.6680500894  0.6563327370  0.6616573637  0.6869409660  0.9161205235  1.0242199898  4800          0.1426673595 
0.6820092664  0.6742039356  0.6657066190  0.6712466008  0.7298747764  0.9660888569  1.0242199898  5100          0.1489919360 
0.6782705139  0.6692665474  0.6604830054  0.6665951052  0.7728085868  0.9702370835  1.0242199898  5400          0.1495854187 
0.6761059731  0.6661180680  0.6702862254  0.6753256047  0.8157423971  0.9244843239  1.0242199898  5700          0.1494442010 
0.6790576197  0.6701252236  0.6701431127  0.6760412194  0.8586762075  0.9205635803  1.0242199898  6000          0.1494135896 
0.6902917658  0.6842933810  0.6633631485  0.6669529126  0.9016100179  0.9470665178  1.0242199898  6300          0.1494182992 
0.7050678879  0.6920930233  0.6849552773  0.6902103907  0.9445438283  0.9110222644  1.0242199898  6600          0.1495213731 
0.6978587145  0.6852951699  0.6693917710  0.6766852726  0.9874776386  0.9155715161  1.0242199898  6900          0.1494566639 
0.6920806426  0.6791413238  0.6596779964  0.6606555031  1.0304114490  0.9366324311  1.0242199898  7200          0.1493758909 
0.7005241409  0.6865831843  0.6804830054  0.6865607557  1.0733452594  0.9052566724  1.0242199898  7500          0.1495283469 
0.6909536502  0.6752057245  0.6693202147  0.6752540432  1.1162790698  0.8732961732  1.0242199898  7800          0.1484276231 
0.6960877265  0.6837209302  0.6835957066  0.6871332475  1.1592128801  0.8752204868  1.0242199898  8100          0.1493014288 
0.7086814189  0.6947406082  0.6860286225  0.6957206240  1.2021466905  0.8579844001  1.0242199898  8400          0.1489042052 
0.7040303393  0.6917352415  0.6787119857  0.6843423501  1.2450805009  0.8753540884  1.0242199898  8700          0.1486440651 
0.7126348366  0.6947406082  0.6821824687  0.6862745098  1.2880143113  0.9246503330  1.0242199898  9000          0.1499313442 
0.7157832597  0.7023255814  0.6912164580  0.6924287963  1.3309481216  0.8156904763  1.0242199898  9300          0.1486417190 
0.7136723851  0.6986046512  0.6915563506  0.6967940461  1.3738819320  0.8860882676  1.0242199898  9600          0.1484317573 
0.7231713207  0.7091949911  0.6927012522  0.6972234149  1.4168157424  0.8165656731  1.0242199898  9900          0.1485733787 
0.7220801059  0.7076207513  0.6917710197  0.6990840132  1.4309838998  0.8817120127  1.0242199898  9999          0.1479811452 
