0
Environment:
	Python: 3.8.11
	PyTorch: 1.9.1+cu102
	Torchvision: 0.10.1+cu102
	CUDA: 10.2
	CUDNN: 7605
	NumPy: 1.21.2
	PIL: 8.3.1
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: DGMaterials
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [6]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 8
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_in_acc   env4_out_acc  env5_in_acc   env5_out_acc  env6_in_acc   env6_out_acc  epoch         loss          mem_gb        step          step_time    
0.0868694097  0.0885931015  0.0881037567  0.0879490482  0.0928980322  0.0891655932  0.0888014311  0.0878059253  0.0922003578  0.0886646629  0.0977817531  0.0930299127  0.0932558140  0.0937455274  0.0000000000  2.7111797333  4.0074415207  0             1.7484850883 
0.5509838998  0.5539573494  0.5795885510  0.5859453270  0.5667799642  0.5675540289  0.5796779964  0.5819378846  0.5771914132  0.5797194790  0.5704114490  0.5702018033  0.5890697674  0.5884499785  0.0429338104  1.4731897187  4.2766914368  300           1.1733888380 
0.6129695886  0.6147846000  0.6207871199  0.6208673250  0.6117352415  0.6077715758  0.6186225403  0.6187920424  0.6147048301  0.6221554315  0.6105724508  0.6100615429  0.6155277281  0.6162873909  0.0858676208  1.2021618026  4.2766914368  600           0.7640245549 
0.6173166369  0.6175039359  0.6497495528  0.6490625447  0.6369409660  0.6290253328  0.6489982111  0.6546443395  0.6451341682  0.6484900530  0.6414311270  0.6435523114  0.6398568873  0.6390439387  0.1288014311  1.1278703521  4.2766914368  900           0.7644212651 
0.6424686941  0.6407614141  0.6704114490  0.6748246744  0.6595348837  0.6525690568  0.6714490161  0.6693144411  0.6677280859  0.6724631458  0.6628801431  0.6683125805  0.6715563506  0.6761127809  0.1717352415  1.0578672659  4.2766914368  1200          0.7623388608 
0.6492128801  0.6456991556  0.6733452594  0.6741090597  0.6596064401  0.6555746386  0.6692486583  0.6735365679  0.6677101968  0.6722484614  0.6598747764  0.6608701875  0.6683184258  0.6710319164  0.2146690519  1.0120906629  4.2766914368  1500          0.7550761127 
0.6506976744  0.6453413482  0.6822182469  0.6771862029  0.6683005367  0.6678116502  0.6800536673  0.6779018177  0.6754025045  0.6810505224  0.6688908766  0.6701016173  0.6824150268  0.6860598254  0.2576028623  0.9573861335  4.2766914368  1800          0.9409795324 
0.6663685152  0.6615858022  0.7018962433  0.7023042794  0.6888193202  0.6829111207  0.6996243292  0.7007299270  0.6959033989  0.7018033491  0.6912880143  0.6867038786  0.7023971377  0.7030914556  0.3005366726  0.9490211728  4.2766914368  2100          0.7726315602 
0.6524686941  0.6516387577  0.6867262970  0.6919278660  0.6745438283  0.6660226134  0.6843470483  0.6824101904  0.6829338104  0.6855588951  0.6720930233  0.6728925147  0.6774955277  0.6805495921  0.3434704830  0.9230893500  4.2766914368  2400          0.7483150069 
0.6747227191  0.6711750394  0.7099105546  0.7086016889  0.7002683363  0.6943609561  0.7081216458  0.7062401603  0.7048658318  0.7043080006  0.7005724508  0.6950050093  0.7036493739  0.7065979677  0.3864042934  0.9043995001  4.2766914368  2700          0.7473168635 
0.6776386404  0.6774724488  0.7188014311  0.7171175039  0.7041323792  0.7003005582  0.7158497317  0.7166881351  0.7137745975  0.7149706598  0.7069051878  0.7026620867  0.7174597496  0.7159725204  0.4293381038  0.8882109892  4.2766914368  3000          0.7416698559 
0.6931305903  0.6892085301  0.7277101968  0.7259911264  0.7147763864  0.7106769715  0.7267978533  0.7216974381  0.7228085868  0.7262058108  0.7176744186  0.7131816230  0.7174776386  0.7183340489  0.4722719141  0.8841566366  4.2766914368  3300          0.7443512702 
0.6891055456  0.6859167024  0.7275313059  0.7244167740  0.7124150268  0.7041648776  0.7209660107  0.7196937169  0.7205545617  0.7211965078  0.7142933810  0.7123228854  0.7101252236  0.7119650780  0.5152057245  0.8653447530  4.2766914368  3600          1.0776706529 
0.7013595707  0.6983683985  0.7303756708  0.7248461428  0.7165474061  0.7083870044  0.7253309481  0.7221983684  0.7265474061  0.7259911264  0.7190161002  0.7136825533  0.7170840787  0.7192643481  0.5581395349  0.8509939421  4.2766914368  3900          0.7465197261 
0.7181932021  0.7102476027  0.7371556351  0.7331472735  0.7237209302  0.7209102619  0.7346690519  0.7268498640  0.7301073345  0.7324316588  0.7257602862  0.7209818234  0.7217531306  0.7229855446  0.6010733453  0.8369229434  4.2766914368  4200          0.7784405096 
0.7121645796  0.7040933162  0.7416636852  0.7422355804  0.7295348837  0.7216974381  0.7367441860  0.7372262774  0.7365474061  0.7360097324  0.7295885510  0.7229139831  0.7322182469  0.7363675397  0.6440071556  0.8055667432  4.2766914368  4500          0.7853226900 
0.7046332737  0.6967940461  0.7372987478  0.7350078718  0.7241860465  0.7178331186  0.7369409660  0.7320738514  0.7329159213  0.7316444826  0.7256529517  0.7192643481  0.7311091234  0.7339344497  0.6869409660  0.8103435831  4.2766914368  4800          0.8268728360 
0.7076923077  0.7001574352  0.7498926655  0.7418777730  0.7366905188  0.7247745814  0.7431484794  0.7413052812  0.7417710197  0.7447402319  0.7352772809  0.7377272077  0.7306440072  0.7324316588  0.7155635063  0.8036749469  4.2766914368  5000          1.4669494283 
