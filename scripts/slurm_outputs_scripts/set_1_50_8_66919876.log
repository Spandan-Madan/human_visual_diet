8
2022-03-19 19:43:15.872323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-03-19 19:43:15.872568: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Task is classification, not lift the flap.
Hard mining set to:both
Using materials: ['main_xml_50_arbitrary_many_styles_repeat_0', 'main_xml_50_arbitrary_many_styles_repeat_1', 'main_xml_50_arbitrary_many_styles_repeat_2', 'main_xml_50_arbitrary_many_styles_repeat_3']
Hotswapped material loader being used.
{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12}
-------------------------------
Annotation Counts
-------------------------------
desk                       4829
trash_bin                  3204
chair                     19905
window                    10204
lamp                       2489
table                     11541
monitor                    3094
file_cabinet               1727
bookshelf                  3902
bed                        3214
sofa                       3550
bathtub                    1988
flowerpot                   227
Total                     69874
-------------------------------

annotations: ../openrooms/annotation_files/train_main_xml_50_v3.json
batch_size: 15
checkpoint: null
git: e22ff54d4e15e859ff3672c5fc808cec0abfc80d
imagedir: ../
imbalance_reweighting: false
learning_rate: 1.0e-05
num_classes: 13
num_decoder_heads: 8
num_decoder_layers: 6
test_annotations: null
test_imagedir: null
uncertainty_gate_type: learned
uncertainty_threshold: 0.8
weighted_prediction: false

No checkpoint was passed.
Starting epoch: 1
batch num:0
overall: tensor(6.8586, device='cuda:0', grad_fn=<AddBackward0>)
Traceback (most recent call last):
  File "train_hotswapped.py", line 205, in <module>
    output_uncertainty_branch , output_main_branch, output_weighted, uncertainty = model(context_images_all, target_images_all, bbox_all)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/spandan/contextual_domain_adaptation/WhenPigsFlyContext/core/model.py", line 99, in forward
    context_encoding = self.context_encoder(context_images)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/spandan/contextual_domain_adaptation/WhenPigsFlyContext/core/model.py", line 156, in forward
    return self.encoder(image)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torchvision/models/densenet.py", line 127, in forward
    new_features = layer(features)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torchvision/models/densenet.py", line 94, in forward
    new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 443, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 439, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.93 GiB total capacity; 10.78 GiB already allocated; 1.12 MiB free; 11.20 GiB reserved in total by PyTorch)
