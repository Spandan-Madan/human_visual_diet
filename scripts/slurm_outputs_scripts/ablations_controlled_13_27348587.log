13
2022-09-22 06:41:44.355964: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-09-22 06:41:44.356186: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
empty_baseline is
False
Using materials: ['main_xml_50_2', 'main_xml_50_3', 'main_xml_50_4', 'main_xml_50_5']
Hotswapped material loader being used.
{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12}
-------------------------------
Annotation Counts
-------------------------------
desk                       4829
trash_bin                  3204
chair                     19905
window                    10204
lamp                       2489
table                     11541
monitor                    3094
file_cabinet               1727
bookshelf                  3902
bed                        3214
sofa                       3550
bathtub                    1988
flowerpot                   227
Total                     69874
-------------------------------

annotations: ../openrooms/annotation_files/train_main_xml_50_v3.json
batch_size: 8
blur_strength: 5
checkpoint: null
context_blur: false
empty_baseline: false
git: fb8600a628428381abf6c19fbf66e4592ce41f87
imagedir: ../
imbalance_reweighting: false
learning_rate: 1.0e-05
num_classes: 13
num_decoder_heads: 8
num_decoder_layers: 6
target_blur: true
test_annotations: ../openrooms/annotation_files/test_main_xml_50_v3.json
test_imagedir: ../
uncertainty_gate_type: learned
uncertainty_threshold: 0.8
weighted_prediction: false

No checkpoint was passed.
Starting epoch: 1
batch num:0
not using contrastive loss
overall: tensor(3.3149, device='cuda:0', grad_fn=<NllLossBackward0>)
Traceback (most recent call last):
  File "train_hotswapped_lift.py", line 231, in <module>
    output_uncertainty_branch , output_main_branch, output_weighted, uncertainty = model(context_images_all, target_images_all, bbox_all)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/spandan/contextual_domain_adaptation/WhenPigsFlyContext/core/model.py", line 99, in forward
    context_encoding = self.context_encoder(context_images)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/spandan/contextual_domain_adaptation/WhenPigsFlyContext/core/model.py", line 156, in forward
    return self.encoder(image)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torchvision/models/densenet.py", line 124, in forward
    new_features = layer(features)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torchvision/models/densenet.py", line 92, in forward
    new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 168, in forward
    return F.batch_norm(
  File "/n/home05/smadan/.conda/envs/domain_adaptation/lib/python3.8/site-packages/torch/nn/functional.py", line 2421, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.93 GiB total capacity; 6.96 GiB already allocated; 4.56 MiB free; 7.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
